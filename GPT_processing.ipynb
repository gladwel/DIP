{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "openai.organization = \"org-RAUgpYO6HKSPQCszhrY71FA6\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# openai.organization = \"\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/summaries.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              title  daoId  \\\n0      1  [1IP-07] Integrate Balancer Boosted Pools in t...      1   \n1      2  [1IP-06] Donation of 1inch DAO Treasury Funds ...      1   \n2      3  [Temperature Check] Should the Uniswap communi...      2   \n3      4                  Aave V3 Harmony - Freeze Reserves      3   \n4      5               Revised ARC: Add 1INCH as collateral      3   \n..   ...                                                ...    ...   \n678  805  [BIP-237] Enable USH - ETH 50/50 Gauge with 10...     12   \n679  806         [BIP-239] Enable bb-a-USD gauge [Ethereum]     12   \n680  807   [BIP-240] Enable rETH/bb-a-wETH Gauge [Arbitrum]     12   \n681  808                        [BIP-241] Aave v3 Migration     12   \n682  809  [1IP-26] Remove st1INCH(v1) Voting | Modify st...      1   \n\n                                     juniorDescription  \\\n0    The proposal is about integrating Balancer Boo...   \n1    The 1inch DAO Treasury is proposing to donate ...   \n2    The Protocol Guild is a council of Ethereum pr...   \n3    The proposal is about freezing all reserves on...   \n4    The proposal seeks to add 1inch Networks 1INCH...   \n..                                                 ...   \n678  This proposal is about adding a gauge to the n...   \n679  This passage is describing a proposal to add a...   \n680  This proposal is for a new pool on Arbitrum cr...   \n681  This proposal is about transitioning from the ...   \n682  This proposal is about modifying the 1inch DAO...   \n\n                                     middleDescription  \\\n0    This proposal calls for the integration of Bal...   \n1    The 1inch DAO is proposing to donate 1 million...   \n2    The authors are proposing that 500,000 UNI (ab...   \n3    The Aave DAO Community, through the governance...   \n4    1inch Network is a decentralized set of protoc...   \n..                                                 ...   \n678  This proposal is about adding a gauge to the n...   \n679  This passage is describing a proposal to add a...   \n680  This proposal is for a new pool on Arbitrum cr...   \n681  This proposal is about transitioning from the ...   \n682  This proposal is about modifying the 1inch DAO...   \n\n                                     seniorDescription        startAt  \\\n0    Simple Summary. This proposal calls for the in...  1651554223000   \n1    Summary. 1inch Network was founded on core val...  1646760014000   \n2    Authors: [Trent]([link]) (PG Member), [Tim]([l...  1654176425000   \n3    title: Aave V3 Harmony - Freeze Reserves. stat...  1657807792000   \n4    Summary. 1inch is a network of decentralized p...  1657638000000   \n..                                                 ...            ...   \n678  [PR with Payload]([link]) Summary: Proposal to...  1680796800000   \n679  [PR with Payload]([link]) Summary This is a pr...  1680796800000   \n680  [link] Summary: > This pool uses the Composabl...  1680796800000   \n681  [link] Motivation. > With the Aave v3 linear p...  1680796800000   \n682  Author: References: [[1IP-11] 1inch Staking Po...  1680789393000   \n\n             endAt                                      author      createdAt  \\\n0    1652159023000  0x824732d3f4eb94a20254cca9de10485ce445bb40  1657200979740   \n1    1647364814000  0x824732d3f4eb94a20254cca9de10485ce445bb40  1657200981507   \n2    1654437600000  0x4c0a466df0628fe8699051b3ac6506653191cc21  1657200982022   \n3    1658138400000  0xd2362dbb5aa708bc454ce5c3f11050c016764fa6  1658239945117   \n4    1657983600000  0xc290cfb8d020c0615e9c63036f4319cc41717e68  1658239945766   \n..             ...                                         ...            ...   \n678  1681142400000  0x9f74662aD05840Ba35d111930501c617920dD68e  1680720307179   \n679  1681142400000  0x9f74662aD05840Ba35d111930501c617920dD68e  1680720307225   \n680  1681142400000  0x512fce9B07Ce64590849115EE6B32fd40eC0f5F3  1680776108847   \n681  1681142400000  0x512fce9B07Ce64590849115EE6B32fd40eC0f5F3  1680777004583   \n682  1681221393000  0x824732D3F4Eb94a20254cca9DE10485Ce445Bb40  1680786006844   \n\n     ... sum_word_density text_word_density sum_sent_density  \\\n0    ...         0.191837          0.195598         0.041667   \n1    ...         0.178295          0.191805         0.042553   \n2    ...         0.205036          0.178934         0.034483   \n3    ...         0.193966          0.194444         0.043478   \n4    ...         0.219048          0.192007         0.042553   \n..   ...              ...               ...              ...   \n678  ...         0.183575          0.190299         0.034783   \n679  ...         0.203390          0.200301         0.041237   \n680  ...         0.205882          0.184189         0.039370   \n681  ...         0.213793          0.180944         0.042553   \n682  ...         0.182510          0.186319         0.020619   \n\n     text_sent_density  sum_punc_count  text_punc_count  text_stopw_count  \\\n0             0.049157               3              110               255   \n1             0.053864               4               77               150   \n2             0.048402              10              317               384   \n3             0.058394               5               34               100   \n4             0.070053               3              430               588   \n..                 ...             ...              ...               ...   \n678           0.042445               9              250               419   \n679           0.067416              14               79                93   \n680           0.050773              18              243               137   \n681           0.039171               9              286               139   \n682           0.041578              12              291               284   \n\n     sum_stopw_count  sum_stopw_density  text_stopw_density  \n0                 18           0.375000            0.358146  \n1                 14           0.297872            0.351288  \n2                 20           0.344828            0.350685  \n3                 17           0.369565            0.364964  \n4                 19           0.404255            0.314439  \n..               ...                ...                 ...  \n678               46           0.400000            0.355688  \n679               38           0.391753            0.348315  \n680               46           0.362205            0.302428  \n681               38           0.404255            0.320276  \n682               33           0.340206            0.302772  \n\n[683 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>daoId</th>\n      <th>juniorDescription</th>\n      <th>middleDescription</th>\n      <th>seniorDescription</th>\n      <th>startAt</th>\n      <th>endAt</th>\n      <th>author</th>\n      <th>createdAt</th>\n      <th>...</th>\n      <th>sum_word_density</th>\n      <th>text_word_density</th>\n      <th>sum_sent_density</th>\n      <th>text_sent_density</th>\n      <th>sum_punc_count</th>\n      <th>text_punc_count</th>\n      <th>text_stopw_count</th>\n      <th>sum_stopw_count</th>\n      <th>sum_stopw_density</th>\n      <th>text_stopw_density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[1IP-07] Integrate Balancer Boosted Pools in t...</td>\n      <td>1</td>\n      <td>The proposal is about integrating Balancer Boo...</td>\n      <td>This proposal calls for the integration of Bal...</td>\n      <td>Simple Summary. This proposal calls for the in...</td>\n      <td>1651554223000</td>\n      <td>1652159023000</td>\n      <td>0x824732d3f4eb94a20254cca9de10485ce445bb40</td>\n      <td>1657200979740</td>\n      <td>...</td>\n      <td>0.191837</td>\n      <td>0.195598</td>\n      <td>0.041667</td>\n      <td>0.049157</td>\n      <td>3</td>\n      <td>110</td>\n      <td>255</td>\n      <td>18</td>\n      <td>0.375000</td>\n      <td>0.358146</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[1IP-06] Donation of 1inch DAO Treasury Funds ...</td>\n      <td>1</td>\n      <td>The 1inch DAO Treasury is proposing to donate ...</td>\n      <td>The 1inch DAO is proposing to donate 1 million...</td>\n      <td>Summary. 1inch Network was founded on core val...</td>\n      <td>1646760014000</td>\n      <td>1647364814000</td>\n      <td>0x824732d3f4eb94a20254cca9de10485ce445bb40</td>\n      <td>1657200981507</td>\n      <td>...</td>\n      <td>0.178295</td>\n      <td>0.191805</td>\n      <td>0.042553</td>\n      <td>0.053864</td>\n      <td>4</td>\n      <td>77</td>\n      <td>150</td>\n      <td>14</td>\n      <td>0.297872</td>\n      <td>0.351288</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[Temperature Check] Should the Uniswap communi...</td>\n      <td>2</td>\n      <td>The Protocol Guild is a council of Ethereum pr...</td>\n      <td>The authors are proposing that 500,000 UNI (ab...</td>\n      <td>Authors: [Trent]([link]) (PG Member), [Tim]([l...</td>\n      <td>1654176425000</td>\n      <td>1654437600000</td>\n      <td>0x4c0a466df0628fe8699051b3ac6506653191cc21</td>\n      <td>1657200982022</td>\n      <td>...</td>\n      <td>0.205036</td>\n      <td>0.178934</td>\n      <td>0.034483</td>\n      <td>0.048402</td>\n      <td>10</td>\n      <td>317</td>\n      <td>384</td>\n      <td>20</td>\n      <td>0.344828</td>\n      <td>0.350685</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Aave V3 Harmony - Freeze Reserves</td>\n      <td>3</td>\n      <td>The proposal is about freezing all reserves on...</td>\n      <td>The Aave DAO Community, through the governance...</td>\n      <td>title: Aave V3 Harmony - Freeze Reserves. stat...</td>\n      <td>1657807792000</td>\n      <td>1658138400000</td>\n      <td>0xd2362dbb5aa708bc454ce5c3f11050c016764fa6</td>\n      <td>1658239945117</td>\n      <td>...</td>\n      <td>0.193966</td>\n      <td>0.194444</td>\n      <td>0.043478</td>\n      <td>0.058394</td>\n      <td>5</td>\n      <td>34</td>\n      <td>100</td>\n      <td>17</td>\n      <td>0.369565</td>\n      <td>0.364964</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Revised ARC: Add 1INCH as collateral</td>\n      <td>3</td>\n      <td>The proposal seeks to add 1inch Networks 1INCH...</td>\n      <td>1inch Network is a decentralized set of protoc...</td>\n      <td>Summary. 1inch is a network of decentralized p...</td>\n      <td>1657638000000</td>\n      <td>1657983600000</td>\n      <td>0xc290cfb8d020c0615e9c63036f4319cc41717e68</td>\n      <td>1658239945766</td>\n      <td>...</td>\n      <td>0.219048</td>\n      <td>0.192007</td>\n      <td>0.042553</td>\n      <td>0.070053</td>\n      <td>3</td>\n      <td>430</td>\n      <td>588</td>\n      <td>19</td>\n      <td>0.404255</td>\n      <td>0.314439</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>805</td>\n      <td>[BIP-237] Enable USH - ETH 50/50 Gauge with 10...</td>\n      <td>12</td>\n      <td>This proposal is about adding a gauge to the n...</td>\n      <td>This proposal is about adding a gauge to the n...</td>\n      <td>[PR with Payload]([link]) Summary: Proposal to...</td>\n      <td>1680796800000</td>\n      <td>1681142400000</td>\n      <td>0x9f74662aD05840Ba35d111930501c617920dD68e</td>\n      <td>1680720307179</td>\n      <td>...</td>\n      <td>0.183575</td>\n      <td>0.190299</td>\n      <td>0.034783</td>\n      <td>0.042445</td>\n      <td>9</td>\n      <td>250</td>\n      <td>419</td>\n      <td>46</td>\n      <td>0.400000</td>\n      <td>0.355688</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>806</td>\n      <td>[BIP-239] Enable bb-a-USD gauge [Ethereum]</td>\n      <td>12</td>\n      <td>This passage is describing a proposal to add a...</td>\n      <td>This passage is describing a proposal to add a...</td>\n      <td>[PR with Payload]([link]) Summary This is a pr...</td>\n      <td>1680796800000</td>\n      <td>1681142400000</td>\n      <td>0x9f74662aD05840Ba35d111930501c617920dD68e</td>\n      <td>1680720307225</td>\n      <td>...</td>\n      <td>0.203390</td>\n      <td>0.200301</td>\n      <td>0.041237</td>\n      <td>0.067416</td>\n      <td>14</td>\n      <td>79</td>\n      <td>93</td>\n      <td>38</td>\n      <td>0.391753</td>\n      <td>0.348315</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>807</td>\n      <td>[BIP-240] Enable rETH/bb-a-wETH Gauge [Arbitrum]</td>\n      <td>12</td>\n      <td>This proposal is for a new pool on Arbitrum cr...</td>\n      <td>This proposal is for a new pool on Arbitrum cr...</td>\n      <td>[link] Summary: &gt; This pool uses the Composabl...</td>\n      <td>1680796800000</td>\n      <td>1681142400000</td>\n      <td>0x512fce9B07Ce64590849115EE6B32fd40eC0f5F3</td>\n      <td>1680776108847</td>\n      <td>...</td>\n      <td>0.205882</td>\n      <td>0.184189</td>\n      <td>0.039370</td>\n      <td>0.050773</td>\n      <td>18</td>\n      <td>243</td>\n      <td>137</td>\n      <td>46</td>\n      <td>0.362205</td>\n      <td>0.302428</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>808</td>\n      <td>[BIP-241] Aave v3 Migration</td>\n      <td>12</td>\n      <td>This proposal is about transitioning from the ...</td>\n      <td>This proposal is about transitioning from the ...</td>\n      <td>[link] Motivation. &gt; With the Aave v3 linear p...</td>\n      <td>1680796800000</td>\n      <td>1681142400000</td>\n      <td>0x512fce9B07Ce64590849115EE6B32fd40eC0f5F3</td>\n      <td>1680777004583</td>\n      <td>...</td>\n      <td>0.213793</td>\n      <td>0.180944</td>\n      <td>0.042553</td>\n      <td>0.039171</td>\n      <td>9</td>\n      <td>286</td>\n      <td>139</td>\n      <td>38</td>\n      <td>0.404255</td>\n      <td>0.320276</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>809</td>\n      <td>[1IP-26] Remove st1INCH(v1) Voting | Modify st...</td>\n      <td>1</td>\n      <td>This proposal is about modifying the 1inch DAO...</td>\n      <td>This proposal is about modifying the 1inch DAO...</td>\n      <td>Author: References: [[1IP-11] 1inch Staking Po...</td>\n      <td>1680789393000</td>\n      <td>1681221393000</td>\n      <td>0x824732D3F4Eb94a20254cca9DE10485Ce445Bb40</td>\n      <td>1680786006844</td>\n      <td>...</td>\n      <td>0.182510</td>\n      <td>0.186319</td>\n      <td>0.020619</td>\n      <td>0.041578</td>\n      <td>12</td>\n      <td>291</td>\n      <td>284</td>\n      <td>33</td>\n      <td>0.340206</td>\n      <td>0.302772</td>\n    </tr>\n  </tbody>\n</table>\n<p>683 rows × 34 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Count amount of tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To count tokens in the seniorDescription column of a dataset without using openai.Completion.create, we can leverage the tiktoken library. This library allows to count tokens in a text string without making an API call to OpenAI."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 4000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "df['num_tokens'] = df['seniorDescription'].apply(lambda x: num_tokens_from_string(x, 'cl100k_base'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526297\n",
      "[3201, 3034, 2970, 2954, 2950, 2940, 2939, 2926, 2896, 2873, 2845, 2844, 2754, 2725, 2724, 2714, 2695, 2684, 2608, 2595, 2587, 2529, 2468, 2440, 2354, 2336, 2271, 2267, 2216, 2210, 2209, 2173, 2171, 2169, 2129, 2126, 2118, 2075, 2051, 2029, 1987, 1986, 1981, 1973, 1973, 1971, 1960, 1941, 1892, 1887, 1885, 1877, 1825, 1811, 1776, 1769, 1763, 1757, 1732, 1730, 1721, 1713, 1701, 1699, 1697, 1693, 1677, 1667, 1665, 1665, 1662, 1655, 1624, 1613, 1611, 1603, 1592, 1588, 1582, 1575, 1561, 1552, 1547, 1527, 1524, 1522, 1512, 1502, 1496, 1493, 1485, 1463, 1451, 1439, 1433, 1400, 1393, 1392, 1388, 1385, 1354, 1345, 1343, 1336, 1336, 1332, 1323, 1303, 1277, 1264, 1262, 1257, 1255, 1254, 1253, 1244, 1243, 1226, 1224, 1215, 1215, 1208, 1197, 1196, 1193, 1187, 1185, 1180, 1174, 1166, 1160, 1145, 1137, 1126, 1126, 1126, 1125, 1124, 1123, 1120, 1118, 1118, 1113, 1111, 1105, 1105, 1101, 1096, 1093, 1092, 1088, 1087, 1084, 1082, 1073, 1073, 1072, 1071, 1061, 1054, 1045, 1045, 1041, 1016, 1012, 1009, 1007, 1007, 1006, 1002, 1000, 995, 987, 987, 984, 977, 974, 968, 967, 963, 958, 957, 952, 945, 943, 942, 941, 931, 927, 923, 921, 914, 906, 904, 895, 894, 893, 890, 886, 885, 884, 884, 880, 880, 880, 876, 875, 875, 871, 870, 868, 867, 864, 857, 856, 852, 849, 849, 843, 841, 839, 831, 827, 827, 822, 821, 817, 815, 813, 813, 812, 807, 807, 803, 802, 802, 799, 796, 794, 790, 787, 784, 782, 779, 777, 774, 773, 773, 771, 771, 767, 767, 766, 766, 766, 766, 766, 763, 762, 760, 759, 754, 751, 750, 749, 744, 742, 742, 742, 741, 735, 733, 732, 730, 723, 722, 721, 720, 719, 719, 718, 716, 711, 711, 711, 711, 707, 703, 700, 698, 697, 691, 689, 687, 687, 686, 686, 685, 684, 682, 679, 679, 677, 668, 665, 661, 659, 657, 654, 654, 647, 646, 643, 643, 642, 641, 641, 640, 639, 638, 631, 629, 628, 628, 628, 627, 625, 621, 618, 618, 618, 617, 608, 606, 606, 606, 605, 604, 600, 598, 597, 597, 593, 588, 584, 584, 579, 577, 576, 575, 574, 574, 573, 573, 573, 572, 569, 567, 567, 567, 567, 566, 566, 566, 562, 561, 560, 558, 555, 553, 552, 550, 546, 546, 546, 544, 543, 542, 537, 536, 531, 531, 531, 531, 528, 526, 525, 524, 522, 518, 517, 512, 511, 511, 511, 508, 506, 504, 504, 502, 491, 491, 490, 489, 485, 485, 484, 483, 479, 478, 477, 473, 472, 472, 472, 472, 471, 471, 470, 470, 469, 469, 466, 466, 465, 462, 462, 459, 457, 455, 454, 453, 453, 453, 450, 446, 446, 444, 444, 444, 442, 441, 437, 433, 432, 431, 430, 427, 425, 420, 418, 416, 415, 414, 413, 412, 411, 411, 404, 402, 398, 397, 397, 395, 394, 391, 387, 387, 386, 384, 383, 382, 379, 378, 377, 371, 370, 369, 368, 366, 365, 362, 361, 361, 357, 353, 353, 350, 349, 349, 346, 346, 346, 343, 340, 340, 339, 338, 336, 335, 335, 334, 330, 330, 330, 329, 327, 319, 317, 316, 314, 311, 311, 311, 311, 311, 311, 310, 310, 310, 307, 307, 307, 304, 300, 300, 298, 296, 295, 292, 291, 290, 289, 287, 285, 284, 284, 283, 277, 275, 269, 266, 266, 264, 262, 261, 260, 259, 257, 257, 255, 254, 253, 252, 247, 246, 246, 244, 243, 243, 242, 240, 240, 239, 238, 237, 235, 232, 228, 227, 227, 227, 224, 223, 221, 220, 212, 210, 209, 207, 206, 206, 202, 202, 202, 201, 200, 198, 198, 196, 196, 196, 191, 191, 190, 189, 187, 185, 185, 184, 184, 182, 182, 181, 181, 181, 180, 179, 179, 179, 178, 178, 177, 177, 177, 177, 176, 175, 175, 174, 174, 174, 174, 174, 173, 173, 173, 172, 171, 169, 166, 164, 161, 159, 158, 158, 157, 157, 155, 154, 152, 151, 150, 149, 149, 148, 145, 145, 143, 140, 140, 136, 135, 134, 133, 132, 130, 130, 128, 126, 125, 122, 122, 121, 116, 114, 110, 108, 108, 107, 107, 105, 99, 95, 93, 90, 88, 88, 82, 69, 65, 62, 62]\n"
     ]
    }
   ],
   "source": [
    "tokens_count = df['num_tokens'].to_list()\n",
    "tokens_count.sort()\n",
    "print(sum(tokens_count))\n",
    "print(tokens_count[::-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Count GPT models pricings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT4 price usage: 26.1$\n",
      "InstructGPT Davinci (price finetung +  price usage): 20.9$ + 83.7$ = 104.6$\n",
      "InstructGPT Curie (price finetung +  price usage): 2.1$ + 8.4$ = 10.5$\n",
      "ChatGPT price usage: 1.1$\n"
     ]
    }
   ],
   "source": [
    "proposals_amount = 1130\n",
    "GPT4_price_for_training = (sum(tokens_count)/1000*0.03  + (685*250/1000)*0.06)\n",
    "Davinci_price_finetung = (sum(tokens_count)/1000  + (685*250/1000))*0.03\n",
    "Davinci_price_usage = (sum(tokens_count)/1000  + (685*250/1000))*0.12\n",
    "ChatGPT_price_usage = (sum(tokens_count)/1000*0.0015  + (685*250/1000)*0.002)\n",
    "Curie_price_finetung = (sum(tokens_count)/1000  + (685*250/1000))*0.003\n",
    "Curie_price_usage = (sum(tokens_count)/1000  + (685*250/1000))*0.012\n",
    "\n",
    "print(f'GPT4 price usage: {round(GPT4_price_for_training, 1)}$')\n",
    "print(f'InstructGPT Davinci (price finetung +  price usage): {round(Davinci_price_finetung, 1)}$ + {round(Davinci_price_usage, 1)}$ = {round(Davinci_price_finetung + Davinci_price_usage, 1)}$')\n",
    "print(f'InstructGPT Curie (price finetung +  price usage): {round(Curie_price_finetung, 1)}$ + {round(Curie_price_usage, 1)}$ = {round(Curie_price_finetung + Curie_price_usage, 1)}$')\n",
    "print(f'ChatGPT price usage: {round(ChatGPT_price_usage, 1)}$')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process GPT4 Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "# Omit reviews that are too long to embed\n",
    "df[\"n_tokens\"] = df['seniorDescription'].apply(lambda x: len(encoding.encode(x)))\n",
    "df = df[df.n_tokens <= max_tokens]\n",
    "print(len(df))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "[3201, 3034, 2970, 2954, 2950, 2940, 2939, 2926, 2896, 2873]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens_list = df['n_tokens'].to_list()\n",
    "n_tokens_list.sort()\n",
    "n_tokens_list[::-1][:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "'Orange who?'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['message']['content']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "df['seniorDescription'].head(2).to_csv('seniorDescriptions_0.txt', index=False, header=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data for GPT4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/summaries.csv')\n",
    "with open('data/summaries_prompt.jsonl', 'w') as jsonlfile:\n",
    "    for i, row in df.iterrows():\n",
    "        data = {\n",
    "            \"model\": \"gpt-4\",\n",
    "            \"max_tokens\": 250,\n",
    "            \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful crypto expert.\"}, {\"role\": \"user\", \"content\": f\"You have following proposal:\\n{row['seniorDescription']}\\nSummarize it into one paragraph with simple language to make it easier to understand:\"}],\n",
    "        }\n",
    "        jsonlfile.write(json.dumps(data) + '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "  # --max_requests_per_minute 300 \\\n",
    "  # --max_tokens_per_minute 88000 \\"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1125.015531539917\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 18min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n",
      "INFO:root:Starting request #3\n",
      "INFO:root:Starting request #4\n",
      "INFO:root:Starting request #5\n",
      "INFO:root:Starting request #6\n",
      "INFO:root:Starting request #7\n",
      "INFO:root:Starting request #8\n",
      "INFO:root:Starting request #9\n",
      "INFO:root:Starting request #10\n",
      "INFO:root:Starting request #11\n",
      "INFO:root:Starting request #12\n",
      "INFO:root:Starting request #13\n",
      "INFO:root:Starting request #14\n",
      "INFO:root:Starting request #15\n",
      "INFO:root:Starting request #16\n",
      "INFO:root:Starting request #17\n",
      "INFO:root:Starting request #18\n",
      "INFO:root:Starting request #19\n",
      "INFO:root:Starting request #20\n",
      "INFO:root:Starting request #21\n",
      "INFO:root:Starting request #22\n",
      "INFO:root:Starting request #23\n",
      "INFO:root:Starting request #24\n",
      "INFO:root:Starting request #25\n",
      "INFO:root:Starting request #26\n",
      "INFO:root:Starting request #27\n",
      "INFO:root:Starting request #28\n",
      "INFO:root:Starting request #29\n",
      "INFO:root:Starting request #30\n",
      "INFO:root:Starting request #31\n",
      "INFO:root:Starting request #32\n",
      "INFO:root:Starting request #33\n",
      "INFO:root:Starting request #34\n",
      "INFO:root:Starting request #35\n",
      "INFO:root:Starting request #36\n",
      "INFO:root:Starting request #37\n",
      "INFO:root:Starting request #38\n",
      "WARNING:root:Request 24 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "D:\\CVUT\\Diplom\\DIP\\Notebooks\\api_request_parallel_processor.py:227: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(f\"Pausing to cool down until {time.ctime(status_tracker.time_of_last_rate_limit_error + seconds_to_pause_after_rate_limit_error)}\")\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:03:33 2023\n",
      "INFO:root:Starting request #39\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:03:33 2023\n",
      "INFO:root:Starting request #24\n",
      "INFO:root:Starting request #40\n",
      "INFO:root:Starting request #41\n",
      "INFO:root:Starting request #42\n",
      "INFO:root:Starting request #43\n",
      "WARNING:root:Request 39 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:03:49 2023\n",
      "INFO:root:Starting request #44\n",
      "INFO:root:Starting request #39\n",
      "INFO:root:Starting request #45\n",
      "INFO:root:Starting request #46\n",
      "INFO:root:Starting request #47\n",
      "INFO:root:Starting request #48\n",
      "INFO:root:Starting request #49\n",
      "WARNING:root:Request 49 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:04:04 2023\n",
      "INFO:root:Starting request #50\n",
      "INFO:root:Starting request #49\n",
      "INFO:root:Starting request #51\n",
      "INFO:root:Starting request #52\n",
      "INFO:root:Starting request #53\n",
      "INFO:root:Starting request #54\n",
      "INFO:root:Starting request #55\n",
      "INFO:root:Starting request #56\n",
      "INFO:root:Starting request #57\n",
      "INFO:root:Starting request #58\n",
      "WARNING:root:Request 58 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:04:21 2023\n",
      "INFO:root:Starting request #59\n",
      "INFO:root:Starting request #58\n",
      "INFO:root:Starting request #60\n",
      "INFO:root:Starting request #61\n",
      "INFO:root:Starting request #62\n",
      "INFO:root:Starting request #63\n",
      "INFO:root:Starting request #64\n",
      "INFO:root:Starting request #65\n",
      "WARNING:root:Request 65 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:04:37 2023\n",
      "INFO:root:Starting request #66\n",
      "INFO:root:Starting request #65\n",
      "INFO:root:Starting request #67\n",
      "INFO:root:Starting request #68\n",
      "INFO:root:Starting request #69\n",
      "INFO:root:Starting request #70\n",
      "INFO:root:Starting request #71\n",
      "INFO:root:Starting request #72\n",
      "INFO:root:Starting request #73\n",
      "INFO:root:Starting request #74\n",
      "INFO:root:Starting request #75\n",
      "INFO:root:Starting request #76\n",
      "WARNING:root:Request 76 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:04:54 2023\n",
      "INFO:root:Starting request #77\n",
      "INFO:root:Starting request #76\n",
      "INFO:root:Starting request #78\n",
      "INFO:root:Starting request #79\n",
      "INFO:root:Starting request #80\n",
      "INFO:root:Starting request #81\n",
      "INFO:root:Starting request #82\n",
      "INFO:root:Starting request #83\n",
      "INFO:root:Starting request #84\n",
      "INFO:root:Starting request #85\n",
      "WARNING:root:Request 85 failed with error {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}\n",
      "INFO:root:Starting request #86\n",
      "INFO:root:Starting request #85\n",
      "INFO:root:Starting request #87\n",
      "INFO:root:Starting request #88\n",
      "INFO:root:Starting request #89\n",
      "INFO:root:Starting request #90\n",
      "INFO:root:Starting request #91\n",
      "INFO:root:Starting request #92\n",
      "INFO:root:Starting request #93\n",
      "INFO:root:Starting request #94\n",
      "INFO:root:Starting request #95\n",
      "INFO:root:Starting request #96\n",
      "INFO:root:Starting request #97\n",
      "INFO:root:Starting request #98\n",
      "INFO:root:Starting request #99\n",
      "INFO:root:Starting request #100\n",
      "INFO:root:Starting request #101\n",
      "INFO:root:Starting request #102\n",
      "INFO:root:Starting request #103\n",
      "INFO:root:Starting request #104\n",
      "WARNING:root:Request 104 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:05:45 2023\n",
      "INFO:root:Starting request #105\n",
      "INFO:root:Starting request #104\n",
      "INFO:root:Starting request #106\n",
      "INFO:root:Starting request #107\n",
      "INFO:root:Starting request #108\n",
      "INFO:root:Starting request #109\n",
      "INFO:root:Starting request #110\n",
      "INFO:root:Starting request #111\n",
      "INFO:root:Starting request #112\n",
      "INFO:root:Starting request #113\n",
      "INFO:root:Starting request #114\n",
      "INFO:root:Starting request #115\n",
      "INFO:root:Starting request #116\n",
      "INFO:root:Starting request #117\n",
      "INFO:root:Starting request #118\n",
      "INFO:root:Starting request #119\n",
      "INFO:root:Starting request #120\n",
      "INFO:root:Starting request #121\n",
      "INFO:root:Starting request #122\n",
      "INFO:root:Starting request #123\n",
      "INFO:root:Starting request #124\n",
      "INFO:root:Starting request #125\n",
      "INFO:root:Starting request #126\n",
      "INFO:root:Starting request #127\n",
      "INFO:root:Starting request #128\n",
      "INFO:root:Starting request #129\n",
      "INFO:root:Starting request #130\n",
      "INFO:root:Starting request #131\n",
      "INFO:root:Starting request #132\n",
      "INFO:root:Starting request #133\n",
      "INFO:root:Starting request #134\n",
      "INFO:root:Starting request #135\n",
      "INFO:root:Starting request #136\n",
      "INFO:root:Starting request #137\n",
      "INFO:root:Starting request #138\n",
      "INFO:root:Starting request #139\n",
      "INFO:root:Starting request #140\n",
      "INFO:root:Starting request #141\n",
      "WARNING:root:Request 141 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:06:42 2023\n",
      "INFO:root:Starting request #142\n",
      "INFO:root:Starting request #141\n",
      "INFO:root:Starting request #143\n",
      "INFO:root:Starting request #144\n",
      "INFO:root:Starting request #145\n",
      "INFO:root:Starting request #146\n",
      "INFO:root:Starting request #147\n",
      "INFO:root:Starting request #148\n",
      "INFO:root:Starting request #149\n",
      "INFO:root:Starting request #150\n",
      "INFO:root:Starting request #151\n",
      "INFO:root:Starting request #152\n",
      "INFO:root:Starting request #153\n",
      "INFO:root:Starting request #154\n",
      "INFO:root:Starting request #155\n",
      "INFO:root:Starting request #156\n",
      "INFO:root:Starting request #157\n",
      "INFO:root:Starting request #158\n",
      "INFO:root:Starting request #159\n",
      "INFO:root:Starting request #160\n",
      "INFO:root:Starting request #161\n",
      "INFO:root:Starting request #162\n",
      "INFO:root:Starting request #163\n",
      "INFO:root:Starting request #164\n",
      "INFO:root:Starting request #165\n",
      "INFO:root:Starting request #166\n",
      "INFO:root:Starting request #167\n",
      "WARNING:root:Request 167 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:07:16 2023\n",
      "INFO:root:Starting request #168\n",
      "INFO:root:Starting request #167\n",
      "INFO:root:Starting request #169\n",
      "INFO:root:Starting request #170\n",
      "INFO:root:Starting request #171\n",
      "INFO:root:Starting request #172\n",
      "INFO:root:Starting request #173\n",
      "INFO:root:Starting request #174\n",
      "INFO:root:Starting request #175\n",
      "INFO:root:Starting request #176\n",
      "INFO:root:Starting request #177\n",
      "INFO:root:Starting request #178\n",
      "INFO:root:Starting request #179\n",
      "INFO:root:Starting request #180\n",
      "INFO:root:Starting request #181\n",
      "INFO:root:Starting request #182\n",
      "INFO:root:Starting request #183\n",
      "INFO:root:Starting request #184\n",
      "INFO:root:Starting request #185\n",
      "INFO:root:Starting request #186\n",
      "INFO:root:Starting request #187\n",
      "INFO:root:Starting request #188\n",
      "INFO:root:Starting request #189\n",
      "INFO:root:Starting request #190\n",
      "INFO:root:Starting request #191\n",
      "INFO:root:Starting request #192\n",
      "INFO:root:Starting request #193\n",
      "INFO:root:Starting request #194\n",
      "INFO:root:Starting request #195\n",
      "INFO:root:Starting request #196\n",
      "INFO:root:Starting request #197\n",
      "INFO:root:Starting request #198\n",
      "INFO:root:Starting request #199\n",
      "WARNING:root:Request 199 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:08:08 2023\n",
      "INFO:root:Starting request #200\n",
      "INFO:root:Starting request #199\n",
      "INFO:root:Starting request #201\n",
      "INFO:root:Starting request #202\n",
      "INFO:root:Starting request #203\n",
      "INFO:root:Starting request #204\n",
      "INFO:root:Starting request #205\n",
      "INFO:root:Starting request #206\n",
      "INFO:root:Starting request #207\n",
      "INFO:root:Starting request #208\n",
      "INFO:root:Starting request #209\n",
      "INFO:root:Starting request #210\n",
      "INFO:root:Starting request #211\n",
      "INFO:root:Starting request #212\n",
      "INFO:root:Starting request #213\n",
      "INFO:root:Starting request #214\n",
      "INFO:root:Starting request #215\n",
      "WARNING:root:Request 215 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:08:42 2023\n",
      "INFO:root:Starting request #216\n",
      "INFO:root:Starting request #215\n",
      "INFO:root:Starting request #217\n",
      "INFO:root:Starting request #218\n",
      "INFO:root:Starting request #219\n",
      "INFO:root:Starting request #220\n",
      "INFO:root:Starting request #221\n",
      "INFO:root:Starting request #222\n",
      "INFO:root:Starting request #223\n",
      "INFO:root:Starting request #224\n",
      "INFO:root:Starting request #225\n",
      "INFO:root:Starting request #226\n",
      "INFO:root:Starting request #227\n",
      "INFO:root:Starting request #228\n",
      "INFO:root:Starting request #229\n",
      "INFO:root:Starting request #230\n",
      "INFO:root:Starting request #231\n",
      "WARNING:root:Request 231 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:09:15 2023\n",
      "INFO:root:Starting request #232\n",
      "INFO:root:Starting request #231\n",
      "INFO:root:Starting request #233\n",
      "INFO:root:Starting request #234\n",
      "INFO:root:Starting request #235\n",
      "INFO:root:Starting request #236\n",
      "INFO:root:Starting request #237\n",
      "INFO:root:Starting request #238\n",
      "INFO:root:Starting request #239\n",
      "INFO:root:Starting request #240\n",
      "INFO:root:Starting request #241\n",
      "INFO:root:Starting request #242\n",
      "INFO:root:Starting request #243\n",
      "INFO:root:Starting request #244\n",
      "INFO:root:Starting request #245\n",
      "INFO:root:Starting request #246\n",
      "INFO:root:Starting request #247\n",
      "INFO:root:Starting request #248\n",
      "INFO:root:Starting request #249\n",
      "INFO:root:Starting request #250\n",
      "INFO:root:Starting request #251\n",
      "INFO:root:Starting request #252\n",
      "INFO:root:Starting request #253\n",
      "INFO:root:Starting request #254\n",
      "INFO:root:Starting request #255\n",
      "INFO:root:Starting request #256\n",
      "INFO:root:Starting request #257\n",
      "INFO:root:Starting request #258\n",
      "INFO:root:Starting request #259\n",
      "WARNING:root:Request 259 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:09:50 2023\n",
      "INFO:root:Starting request #260\n",
      "INFO:root:Starting request #259\n",
      "INFO:root:Starting request #261\n",
      "INFO:root:Starting request #262\n",
      "INFO:root:Starting request #263\n",
      "INFO:root:Starting request #264\n",
      "INFO:root:Starting request #265\n",
      "INFO:root:Starting request #266\n",
      "INFO:root:Starting request #267\n",
      "INFO:root:Starting request #268\n",
      "INFO:root:Starting request #269\n",
      "INFO:root:Starting request #270\n",
      "INFO:root:Starting request #271\n",
      "INFO:root:Starting request #272\n",
      "INFO:root:Starting request #273\n",
      "INFO:root:Starting request #274\n",
      "INFO:root:Starting request #275\n",
      "INFO:root:Starting request #276\n",
      "INFO:root:Starting request #277\n",
      "INFO:root:Starting request #278\n",
      "INFO:root:Starting request #279\n",
      "INFO:root:Starting request #280\n",
      "INFO:root:Starting request #281\n",
      "INFO:root:Starting request #282\n",
      "INFO:root:Starting request #283\n",
      "INFO:root:Starting request #284\n",
      "INFO:root:Starting request #285\n",
      "INFO:root:Starting request #286\n",
      "INFO:root:Starting request #287\n",
      "INFO:root:Starting request #288\n",
      "WARNING:root:Request 288 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:10:34 2023\n",
      "INFO:root:Starting request #289\n",
      "INFO:root:Starting request #288\n",
      "INFO:root:Starting request #290\n",
      "INFO:root:Starting request #291\n",
      "INFO:root:Starting request #292\n",
      "INFO:root:Starting request #293\n",
      "INFO:root:Starting request #294\n",
      "INFO:root:Starting request #295\n",
      "INFO:root:Starting request #296\n",
      "INFO:root:Starting request #297\n",
      "INFO:root:Starting request #298\n",
      "INFO:root:Starting request #299\n",
      "INFO:root:Starting request #300\n",
      "INFO:root:Starting request #301\n",
      "INFO:root:Starting request #302\n",
      "INFO:root:Starting request #303\n",
      "INFO:root:Starting request #304\n",
      "INFO:root:Starting request #305\n",
      "INFO:root:Starting request #306\n",
      "INFO:root:Starting request #307\n",
      "INFO:root:Starting request #308\n",
      "INFO:root:Starting request #309\n",
      "INFO:root:Starting request #310\n",
      "WARNING:root:Request 310 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:11:03 2023\n",
      "INFO:root:Starting request #311\n",
      "INFO:root:Starting request #310\n",
      "INFO:root:Starting request #312\n",
      "INFO:root:Starting request #313\n",
      "INFO:root:Starting request #314\n",
      "INFO:root:Starting request #315\n",
      "INFO:root:Starting request #316\n",
      "INFO:root:Starting request #317\n",
      "INFO:root:Starting request #318\n",
      "INFO:root:Starting request #319\n",
      "INFO:root:Starting request #320\n",
      "INFO:root:Starting request #321\n",
      "INFO:root:Starting request #322\n",
      "INFO:root:Starting request #323\n",
      "INFO:root:Starting request #324\n",
      "INFO:root:Starting request #325\n",
      "INFO:root:Starting request #326\n",
      "INFO:root:Starting request #327\n",
      "WARNING:root:Request 327 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:11:30 2023\n",
      "INFO:root:Starting request #328\n",
      "INFO:root:Starting request #327\n",
      "INFO:root:Starting request #329\n",
      "INFO:root:Starting request #330\n",
      "INFO:root:Starting request #331\n",
      "INFO:root:Starting request #332\n",
      "INFO:root:Starting request #333\n",
      "INFO:root:Starting request #334\n",
      "INFO:root:Starting request #335\n",
      "INFO:root:Starting request #336\n",
      "INFO:root:Starting request #337\n",
      "INFO:root:Starting request #338\n",
      "INFO:root:Starting request #339\n",
      "INFO:root:Starting request #340\n",
      "INFO:root:Starting request #341\n",
      "INFO:root:Starting request #342\n",
      "WARNING:root:Request 342 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:11:52 2023\n",
      "INFO:root:Starting request #343\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:11:52 2023\n",
      "INFO:root:Starting request #342\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:11:52 2023\n",
      "INFO:root:Starting request #344\n",
      "INFO:root:Starting request #345\n",
      "INFO:root:Starting request #346\n",
      "INFO:root:Starting request #347\n",
      "INFO:root:Starting request #348\n",
      "INFO:root:Starting request #349\n",
      "INFO:root:Starting request #350\n",
      "INFO:root:Starting request #351\n",
      "INFO:root:Starting request #352\n",
      "WARNING:root:Request 352 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:12:13 2023\n",
      "INFO:root:Starting request #353\n",
      "INFO:root:Starting request #352\n",
      "INFO:root:Starting request #354\n",
      "INFO:root:Starting request #355\n",
      "INFO:root:Starting request #356\n",
      "INFO:root:Starting request #357\n",
      "INFO:root:Starting request #358\n",
      "INFO:root:Starting request #359\n",
      "INFO:root:Starting request #360\n",
      "INFO:root:Starting request #361\n",
      "INFO:root:Starting request #362\n",
      "WARNING:root:Request 362 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:12:29 2023\n",
      "INFO:root:Starting request #363\n",
      "INFO:root:Starting request #362\n",
      "INFO:root:Starting request #364\n",
      "INFO:root:Starting request #365\n",
      "INFO:root:Starting request #366\n",
      "INFO:root:Starting request #367\n",
      "INFO:root:Starting request #368\n",
      "INFO:root:Starting request #369\n",
      "INFO:root:Starting request #370\n",
      "INFO:root:Starting request #371\n",
      "INFO:root:Starting request #372\n",
      "WARNING:root:Request 372 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:12:48 2023\n",
      "INFO:root:Starting request #373\n",
      "INFO:root:Starting request #372\n",
      "INFO:root:Starting request #374\n",
      "INFO:root:Starting request #375\n",
      "INFO:root:Starting request #376\n",
      "INFO:root:Starting request #377\n",
      "INFO:root:Starting request #378\n",
      "INFO:root:Starting request #379\n",
      "INFO:root:Starting request #380\n",
      "WARNING:root:Request 380 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:13:06 2023\n",
      "INFO:root:Starting request #381\n",
      "INFO:root:Starting request #380\n",
      "INFO:root:Starting request #382\n",
      "INFO:root:Starting request #383\n",
      "INFO:root:Starting request #384\n",
      "INFO:root:Starting request #385\n",
      "INFO:root:Starting request #386\n",
      "INFO:root:Starting request #387\n",
      "INFO:root:Starting request #388\n",
      "INFO:root:Starting request #389\n",
      "INFO:root:Starting request #390\n",
      "INFO:root:Starting request #391\n",
      "INFO:root:Starting request #392\n",
      "WARNING:root:Request 392 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:13:47 2023\n",
      "INFO:root:Starting request #393\n",
      "INFO:root:Starting request #392\n",
      "INFO:root:Starting request #394\n",
      "INFO:root:Starting request #395\n",
      "INFO:root:Starting request #396\n",
      "INFO:root:Starting request #397\n",
      "INFO:root:Starting request #398\n",
      "INFO:root:Starting request #399\n",
      "INFO:root:Starting request #400\n",
      "INFO:root:Starting request #401\n",
      "INFO:root:Starting request #402\n",
      "INFO:root:Starting request #403\n",
      "INFO:root:Starting request #404\n",
      "INFO:root:Starting request #405\n",
      "INFO:root:Starting request #406\n",
      "INFO:root:Starting request #407\n",
      "INFO:root:Starting request #408\n",
      "INFO:root:Starting request #409\n",
      "INFO:root:Starting request #410\n",
      "INFO:root:Starting request #411\n",
      "INFO:root:Starting request #412\n",
      "INFO:root:Starting request #413\n",
      "INFO:root:Starting request #414\n",
      "INFO:root:Starting request #415\n",
      "INFO:root:Starting request #416\n",
      "INFO:root:Starting request #417\n",
      "INFO:root:Starting request #418\n",
      "INFO:root:Starting request #419\n",
      "INFO:root:Starting request #420\n",
      "INFO:root:Starting request #421\n",
      "INFO:root:Starting request #422\n",
      "INFO:root:Starting request #423\n",
      "INFO:root:Starting request #424\n",
      "INFO:root:Starting request #425\n",
      "INFO:root:Starting request #426\n",
      "INFO:root:Starting request #427\n",
      "INFO:root:Starting request #428\n",
      "INFO:root:Starting request #429\n",
      "INFO:root:Starting request #430\n",
      "INFO:root:Starting request #431\n",
      "INFO:root:Starting request #432\n",
      "INFO:root:Starting request #433\n",
      "INFO:root:Starting request #434\n",
      "INFO:root:Starting request #435\n",
      "INFO:root:Starting request #436\n",
      "INFO:root:Starting request #437\n",
      "INFO:root:Starting request #438\n",
      "INFO:root:Starting request #439\n",
      "INFO:root:Starting request #440\n",
      "INFO:root:Starting request #441\n",
      "INFO:root:Starting request #442\n",
      "INFO:root:Starting request #443\n",
      "INFO:root:Starting request #444\n",
      "INFO:root:Starting request #445\n",
      "INFO:root:Starting request #446\n",
      "INFO:root:Starting request #447\n",
      "INFO:root:Starting request #448\n",
      "WARNING:root:Request 448 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:15:20 2023\n",
      "INFO:root:Starting request #449\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:15:20 2023\n",
      "INFO:root:Starting request #448\n",
      "INFO:root:Starting request #450\n",
      "INFO:root:Starting request #451\n",
      "INFO:root:Starting request #452\n",
      "INFO:root:Starting request #453\n",
      "INFO:root:Starting request #454\n",
      "INFO:root:Starting request #455\n",
      "INFO:root:Starting request #456\n",
      "INFO:root:Starting request #457\n",
      "INFO:root:Starting request #458\n",
      "INFO:root:Starting request #459\n",
      "INFO:root:Starting request #460\n",
      "INFO:root:Starting request #461\n",
      "INFO:root:Starting request #462\n",
      "INFO:root:Starting request #463\n",
      "INFO:root:Starting request #464\n",
      "INFO:root:Starting request #465\n",
      "INFO:root:Starting request #466\n",
      "INFO:root:Starting request #467\n",
      "INFO:root:Starting request #468\n",
      "INFO:root:Starting request #469\n",
      "INFO:root:Starting request #470\n",
      "INFO:root:Starting request #471\n",
      "WARNING:root:Request 471 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:15:57 2023\n",
      "INFO:root:Starting request #472\n",
      "INFO:root:Starting request #471\n",
      "INFO:root:Starting request #473\n",
      "INFO:root:Starting request #474\n",
      "INFO:root:Starting request #475\n",
      "INFO:root:Starting request #476\n",
      "INFO:root:Starting request #477\n",
      "INFO:root:Starting request #478\n",
      "INFO:root:Starting request #479\n",
      "INFO:root:Starting request #480\n",
      "INFO:root:Starting request #481\n",
      "INFO:root:Starting request #482\n",
      "INFO:root:Starting request #483\n",
      "INFO:root:Starting request #484\n",
      "INFO:root:Starting request #485\n",
      "INFO:root:Starting request #486\n",
      "INFO:root:Starting request #487\n",
      "INFO:root:Starting request #488\n",
      "INFO:root:Starting request #489\n",
      "INFO:root:Starting request #490\n",
      "INFO:root:Starting request #491\n",
      "INFO:root:Starting request #492\n",
      "INFO:root:Starting request #493\n",
      "WARNING:root:Request 493 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:16:33 2023\n",
      "INFO:root:Starting request #494\n",
      "INFO:root:Starting request #493\n",
      "INFO:root:Starting request #495\n",
      "INFO:root:Starting request #496\n",
      "INFO:root:Starting request #497\n",
      "INFO:root:Starting request #498\n",
      "INFO:root:Starting request #499\n",
      "INFO:root:Starting request #500\n",
      "INFO:root:Starting request #501\n",
      "INFO:root:Starting request #502\n",
      "INFO:root:Starting request #503\n",
      "INFO:root:Starting request #504\n",
      "INFO:root:Starting request #505\n",
      "INFO:root:Starting request #506\n",
      "INFO:root:Starting request #507\n",
      "INFO:root:Starting request #508\n",
      "WARNING:root:Request 508 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:17:00 2023\n",
      "INFO:root:Starting request #509\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:17:00 2023\n",
      "INFO:root:Starting request #508\n",
      "INFO:root:Starting request #510\n",
      "INFO:root:Starting request #511\n",
      "INFO:root:Starting request #512\n",
      "INFO:root:Starting request #513\n",
      "INFO:root:Starting request #514\n",
      "INFO:root:Starting request #515\n",
      "INFO:root:Starting request #516\n",
      "INFO:root:Starting request #517\n",
      "INFO:root:Starting request #518\n",
      "INFO:root:Starting request #519\n",
      "INFO:root:Starting request #520\n",
      "INFO:root:Starting request #521\n",
      "INFO:root:Starting request #522\n",
      "INFO:root:Starting request #523\n",
      "INFO:root:Starting request #524\n",
      "INFO:root:Starting request #525\n",
      "INFO:root:Starting request #526\n",
      "INFO:root:Starting request #527\n",
      "INFO:root:Starting request #528\n",
      "INFO:root:Starting request #529\n",
      "INFO:root:Starting request #530\n",
      "INFO:root:Starting request #531\n",
      "INFO:root:Starting request #532\n",
      "INFO:root:Starting request #533\n",
      "INFO:root:Starting request #534\n",
      "INFO:root:Starting request #535\n",
      "INFO:root:Starting request #536\n",
      "INFO:root:Starting request #537\n",
      "INFO:root:Starting request #538\n",
      "INFO:root:Starting request #539\n",
      "INFO:root:Starting request #540\n",
      "INFO:root:Starting request #541\n",
      "INFO:root:Starting request #542\n",
      "INFO:root:Starting request #543\n",
      "INFO:root:Starting request #544\n",
      "INFO:root:Starting request #545\n",
      "INFO:root:Starting request #546\n",
      "INFO:root:Starting request #547\n",
      "INFO:root:Starting request #548\n",
      "INFO:root:Starting request #549\n",
      "INFO:root:Starting request #550\n",
      "INFO:root:Starting request #551\n",
      "INFO:root:Starting request #552\n",
      "INFO:root:Starting request #553\n",
      "INFO:root:Starting request #554\n",
      "INFO:root:Starting request #555\n",
      "INFO:root:Starting request #556\n",
      "WARNING:root:Request 556 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:18:21 2023\n",
      "INFO:root:Starting request #557\n",
      "INFO:root:Starting request #556\n",
      "INFO:root:Starting request #558\n",
      "INFO:root:Starting request #559\n",
      "INFO:root:Starting request #560\n",
      "INFO:root:Starting request #561\n",
      "INFO:root:Starting request #562\n",
      "INFO:root:Starting request #563\n",
      "INFO:root:Starting request #564\n",
      "INFO:root:Starting request #565\n",
      "INFO:root:Starting request #566\n",
      "INFO:root:Starting request #567\n",
      "INFO:root:Starting request #568\n",
      "WARNING:root:Request 568 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:18:48 2023\n",
      "INFO:root:Starting request #569\n",
      "INFO:root:Starting request #568\n",
      "INFO:root:Starting request #570\n",
      "INFO:root:Starting request #571\n",
      "INFO:root:Starting request #572\n",
      "INFO:root:Starting request #573\n",
      "INFO:root:Starting request #574\n",
      "INFO:root:Starting request #575\n",
      "INFO:root:Starting request #576\n",
      "INFO:root:Starting request #577\n",
      "INFO:root:Starting request #578\n",
      "INFO:root:Starting request #579\n",
      "INFO:root:Starting request #580\n",
      "INFO:root:Starting request #581\n",
      "INFO:root:Starting request #582\n",
      "INFO:root:Starting request #583\n",
      "INFO:root:Starting request #584\n",
      "INFO:root:Starting request #585\n",
      "INFO:root:Starting request #586\n",
      "INFO:root:Starting request #587\n",
      "INFO:root:Starting request #588\n",
      "INFO:root:Starting request #589\n",
      "INFO:root:Starting request #590\n",
      "INFO:root:Starting request #591\n",
      "INFO:root:Starting request #592\n",
      "INFO:root:Starting request #593\n",
      "INFO:root:Starting request #594\n",
      "INFO:root:Starting request #595\n",
      "INFO:root:Starting request #596\n",
      "WARNING:root:Request 596 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:19:46 2023\n",
      "INFO:root:Starting request #597\n",
      "INFO:root:Starting request #596\n",
      "INFO:root:Starting request #598\n",
      "INFO:root:Starting request #599\n",
      "INFO:root:Starting request #600\n",
      "INFO:root:Starting request #601\n",
      "INFO:root:Starting request #602\n",
      "INFO:root:Starting request #603\n",
      "INFO:root:Starting request #604\n",
      "INFO:root:Starting request #605\n",
      "INFO:root:Starting request #606\n",
      "INFO:root:Starting request #607\n",
      "INFO:root:Starting request #608\n",
      "INFO:root:Starting request #609\n",
      "INFO:root:Starting request #610\n",
      "INFO:root:Starting request #611\n",
      "INFO:root:Starting request #612\n",
      "INFO:root:Starting request #613\n",
      "INFO:root:Starting request #614\n",
      "INFO:root:Starting request #615\n",
      "INFO:root:Starting request #616\n",
      "INFO:root:Starting request #617\n",
      "INFO:root:Starting request #618\n",
      "INFO:root:Starting request #619\n",
      "INFO:root:Starting request #620\n",
      "INFO:root:Starting request #621\n",
      "INFO:root:Starting request #622\n",
      "INFO:root:Starting request #623\n",
      "INFO:root:Starting request #624\n",
      "INFO:root:Starting request #625\n",
      "INFO:root:Starting request #626\n",
      "INFO:root:Starting request #627\n",
      "INFO:root:Starting request #628\n",
      "INFO:root:Starting request #629\n",
      "INFO:root:Starting request #630\n",
      "INFO:root:Starting request #631\n",
      "INFO:root:Starting request #632\n",
      "INFO:root:Starting request #633\n",
      "INFO:root:Starting request #634\n",
      "INFO:root:Starting request #635\n",
      "WARNING:root:Request 635 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:20:44 2023\n",
      "INFO:root:Starting request #636\n",
      "INFO:root:Starting request #635\n",
      "INFO:root:Starting request #637\n",
      "INFO:root:Starting request #638\n",
      "INFO:root:Starting request #639\n",
      "INFO:root:Starting request #640\n",
      "INFO:root:Starting request #641\n",
      "INFO:root:Starting request #642\n",
      "INFO:root:Starting request #643\n",
      "INFO:root:Starting request #644\n",
      "WARNING:root:Request 644 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:20:59 2023\n",
      "INFO:root:Starting request #645\n",
      "INFO:root:Starting request #644\n",
      "INFO:root:Starting request #646\n",
      "INFO:root:Starting request #647\n",
      "INFO:root:Starting request #648\n",
      "INFO:root:Starting request #649\n",
      "INFO:root:Starting request #650\n",
      "INFO:root:Starting request #651\n",
      "INFO:root:Starting request #652\n",
      "INFO:root:Starting request #653\n",
      "INFO:root:Starting request #654\n",
      "INFO:root:Starting request #655\n",
      "INFO:root:Starting request #656\n",
      "WARNING:root:Request 656 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:21:15 2023\n",
      "INFO:root:Starting request #657\n",
      "INFO:root:Starting request #656\n",
      "INFO:root:Starting request #658\n",
      "INFO:root:Starting request #659\n",
      "INFO:root:Starting request #660\n",
      "INFO:root:Starting request #661\n",
      "INFO:root:Starting request #662\n",
      "INFO:root:Starting request #663\n",
      "INFO:root:Starting request #664\n",
      "INFO:root:Starting request #665\n",
      "INFO:root:Starting request #666\n",
      "INFO:root:Starting request #667\n",
      "INFO:root:Starting request #668\n",
      "INFO:root:Starting request #669\n",
      "WARNING:root:Request 669 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-RAUgpYO6HKSPQCszhrY71FA6 on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "WARNING:root:Pausing to cool down until Wed Jun 28 17:21:34 2023\n",
      "INFO:root:Starting request #670\n",
      "INFO:root:Starting request #669\n",
      "INFO:root:Starting request #671\n",
      "INFO:root:Starting request #672\n",
      "INFO:root:Starting request #673\n",
      "INFO:root:Starting request #674\n",
      "INFO:root:Starting request #675\n",
      "INFO:root:Starting request #676\n",
      "INFO:root:Starting request #677\n",
      "INFO:root:Starting request #678\n",
      "INFO:root:Starting request #679\n",
      "INFO:root:Starting request #680\n",
      "INFO:root:Starting request #681\n",
      "INFO:root:Starting request #682\n",
      "INFO:root:Parallel processing complete. Results saved to data\\summaries_GPT4_answers_5-02.jsonl\n",
      "WARNING:root:33 rate limit errors received. Consider running at a lower rate.\n",
      "Exception ignored in: <function _ProactorBasePipeTransport.__del__ at 0x000001D9306C71F0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Herman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\proactor_events.py\", line 116, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\Herman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\proactor_events.py\", line 108, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\Herman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 751, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\Herman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 515, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "!python Notebooks\\api_request_parallel_processor.py \\\n",
    "  --requests_filepath data\\summaries_prompt.jsonl \\\n",
    "  --save_filepath data\\summaries_GPT4_answers_5-02.jsonl \\\n",
    "  --request_url https://api.openai.com/v1/chat/completions \\\n",
    "  --max_requests_per_minute 100 \\\n",
    "  --max_tokens_per_minute 40000 \\\n",
    "  --token_encoding_name cl100k_base \\\n",
    "  --max_attempts 5 \\\n",
    "  --logging_level 20\n",
    "print(f'Time: {time.time() - start}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "parsed_GPT_3_5_turbo_list = []\n",
    "with open('data/summaries_GPT3_3_5_turbo_answers_4-38.jsonl', 'r') as jsonlfile:\n",
    "    for i, line in enumerate(jsonlfile):\n",
    "        data = json.loads(line)\n",
    "        summary = data[1]['choices'][0]['message']['content']\n",
    "        text = data[0]['messages'][1]['content'][29:-86] # Remove prompt\n",
    "        parsed_GPT_3_5_turbo_list.append((text, summary))  # Add the proposal to the DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "parsed_GPT_4_list = []\n",
    "with open('data/summaries_GPT4_answers_5-02.jsonl', 'r') as jsonlfile:\n",
    "    for i, line in enumerate(jsonlfile):\n",
    "        data = json.loads(line)\n",
    "        summary = data[1]['choices'][0]['message']['content']\n",
    "        text = data[0]['messages'][1]['content'][29:-86] # Remove prompt\n",
    "        parsed_GPT_4_list.append((text, summary))  # Add the proposal to the DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/summaries.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "GPT4_summary_dict = {text: summary for text, summary in parsed_GPT_4_list}\n",
    "GPT3_5_turbo_summary_dict = {text: summary for text, summary in parsed_GPT_3_5_turbo_list}\n",
    "\n",
    "df['GPT4_summary'] = df['seniorDescription'].map(GPT4_summary_dict)\n",
    "df['GPT3_5_turbo_summary'] = df['seniorDescription'].map(GPT3_5_turbo_summary_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              title  daoId  \\\n0      1  [1IP-07] Integrate Balancer Boosted Pools in t...      1   \n1      2  [1IP-06] Donation of 1inch DAO Treasury Funds ...      1   \n2      3  [Temperature Check] Should the Uniswap communi...      2   \n3      4                  Aave V3 Harmony - Freeze Reserves      3   \n4      5               Revised ARC: Add 1INCH as collateral      3   \n..   ...                                                ...    ...   \n678  805  [BIP-237] Enable USH - ETH 50/50 Gauge with 10...     12   \n679  806         [BIP-239] Enable bb-a-USD gauge [Ethereum]     12   \n680  807   [BIP-240] Enable rETH/bb-a-wETH Gauge [Arbitrum]     12   \n681  808                        [BIP-241] Aave v3 Migration     12   \n682  809  [1IP-26] Remove st1INCH(v1) Voting | Modify st...      1   \n\n                                     juniorDescription  \\\n0    The proposal is about integrating Balancer Boo...   \n1    The 1inch DAO Treasury is proposing to donate ...   \n2    The Protocol Guild is a council of Ethereum pr...   \n3    The proposal is about freezing all reserves on...   \n4    The proposal seeks to add 1inch Networks 1INCH...   \n..                                                 ...   \n678  This proposal is about adding a gauge to the n...   \n679  This passage is describing a proposal to add a...   \n680  This proposal is for a new pool on Arbitrum cr...   \n681  This proposal is about transitioning from the ...   \n682  This proposal is about modifying the 1inch DAO...   \n\n                                     middleDescription  \\\n0    This proposal calls for the integration of Bal...   \n1    The 1inch DAO is proposing to donate 1 million...   \n2    The authors are proposing that 500,000 UNI (ab...   \n3    The Aave DAO Community, through the governance...   \n4    1inch Network is a decentralized set of protoc...   \n..                                                 ...   \n678  This proposal is about adding a gauge to the n...   \n679  This passage is describing a proposal to add a...   \n680  This proposal is for a new pool on Arbitrum cr...   \n681  This proposal is about transitioning from the ...   \n682  This proposal is about modifying the 1inch DAO...   \n\n                                     seniorDescription        startAt  \\\n0    Simple Summary. This proposal calls for the in...  1651554223000   \n1    Summary. 1inch Network was founded on core val...  1646760014000   \n2    Authors: [Trent]([link]) (PG Member), [Tim]([l...  1654176425000   \n3    title: Aave V3 Harmony - Freeze Reserves. stat...  1657807792000   \n4    Summary. 1inch is a network of decentralized p...  1657638000000   \n..                                                 ...            ...   \n678  [PR with Payload]([link]) Summary: Proposal to...  1680796800000   \n679  [PR with Payload]([link]) Summary This is a pr...  1680796800000   \n680  [link] Summary: > This pool uses the Composabl...  1680796800000   \n681  [link] Motivation. > With the Aave v3 linear p...  1680796800000   \n682  Author: References: [[1IP-11] 1inch Staking Po...  1680789393000   \n\n             endAt                                      author      createdAt  \\\n0    1652159023000  0x824732d3f4eb94a20254cca9de10485ce445bb40  1657200979740   \n1    1647364814000  0x824732d3f4eb94a20254cca9de10485ce445bb40  1657200981507   \n2    1654437600000  0x4c0a466df0628fe8699051b3ac6506653191cc21  1657200982022   \n3    1658138400000  0xd2362dbb5aa708bc454ce5c3f11050c016764fa6  1658239945117   \n4    1657983600000  0xc290cfb8d020c0615e9c63036f4319cc41717e68  1658239945766   \n..             ...                                         ...            ...   \n678  1681142400000  0x9f74662aD05840Ba35d111930501c617920dD68e  1680720307179   \n679  1681142400000  0x9f74662aD05840Ba35d111930501c617920dD68e  1680720307225   \n680  1681142400000  0x512fce9B07Ce64590849115EE6B32fd40eC0f5F3  1680776108847   \n681  1681142400000  0x512fce9B07Ce64590849115EE6B32fd40eC0f5F3  1680777004583   \n682  1681221393000  0x824732D3F4Eb94a20254cca9DE10485Ce445Bb40  1680786006844   \n\n     ... sum_sent_density text_sent_density sum_punc_count  text_punc_count  \\\n0    ...         0.041667          0.049157              3              110   \n1    ...         0.042553          0.053864              4               77   \n2    ...         0.034483          0.048402             10              317   \n3    ...         0.043478          0.058394              5               34   \n4    ...         0.042553          0.070053              3              430   \n..   ...              ...               ...            ...              ...   \n678  ...         0.034783          0.042445              9              250   \n679  ...         0.041237          0.067416             14               79   \n680  ...         0.039370          0.050773             18              243   \n681  ...         0.042553          0.039171              9              286   \n682  ...         0.020619          0.041578             12              291   \n\n     text_stopw_count  sum_stopw_count  sum_stopw_density  text_stopw_density  \\\n0                 255               18           0.375000            0.358146   \n1                 150               14           0.297872            0.351288   \n2                 384               20           0.344828            0.350685   \n3                 100               17           0.369565            0.364964   \n4                 588               19           0.404255            0.314439   \n..                ...              ...                ...                 ...   \n678               419               46           0.400000            0.355688   \n679                93               38           0.391753            0.348315   \n680               137               46           0.362205            0.302428   \n681               139               38           0.404255            0.320276   \n682               284               33           0.340206            0.302772   \n\n                                          GPT4_summary  \\\n0    This proposal suggests adding Balancer Boosted...   \n1    The 1inch Network wants to donate $1 million f...   \n2    The authors of this proposal are suggesting th...   \n3    This proposal by 3SE Holdings aims to address ...   \n4    This proposal suggests onboarding 1INCH, the t...   \n..                                                 ...   \n678  UnshETH, a project aimed at decentralizing cry...   \n679  This proposal is about adding a new feature, c...   \n680  This proposal suggests creating a new pool, rE...   \n681  This proposal is about transitioning from old ...   \n682  This proposal suggests changes to the 1inch DA...   \n\n                                  GPT3_5_turbo_summary  \n0    This proposal suggests integrating Balancer Bo...  \n1    This proposal suggests donating 1 million USDC...  \n2    This proposal suggests that the Uniswap commun...  \n3    The proposal suggests freezing all reserves in...  \n4    The proposal suggests adding the 1inch Network...  \n..                                                 ...  \n678  This proposal suggests adding gauge support fo...  \n679  This proposal suggests adding a bb-a-USD gauge...  \n680  This proposal suggests creating a new pool cal...  \n681  The proposal is to transition from the old Aav...  \n682  This proposal suggests changes to the governan...  \n\n[683 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>daoId</th>\n      <th>juniorDescription</th>\n      <th>middleDescription</th>\n      <th>seniorDescription</th>\n      <th>startAt</th>\n      <th>endAt</th>\n      <th>author</th>\n      <th>createdAt</th>\n      <th>...</th>\n      <th>sum_sent_density</th>\n      <th>text_sent_density</th>\n      <th>sum_punc_count</th>\n      <th>text_punc_count</th>\n      <th>text_stopw_count</th>\n      <th>sum_stopw_count</th>\n      <th>sum_stopw_density</th>\n      <th>text_stopw_density</th>\n      <th>GPT4_summary</th>\n      <th>GPT3_5_turbo_summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[1IP-07] Integrate Balancer Boosted Pools in t...</td>\n      <td>1</td>\n      <td>The proposal is about integrating Balancer Boo...</td>\n      <td>This proposal calls for the integration of Bal...</td>\n      <td>Simple Summary. This proposal calls for the in...</td>\n      <td>1651554223000</td>\n      <td>1652159023000</td>\n      <td>0x824732d3f4eb94a20254cca9de10485ce445bb40</td>\n      <td>1657200979740</td>\n      <td>...</td>\n      <td>0.041667</td>\n      <td>0.049157</td>\n      <td>3</td>\n      <td>110</td>\n      <td>255</td>\n      <td>18</td>\n      <td>0.375000</td>\n      <td>0.358146</td>\n      <td>This proposal suggests adding Balancer Boosted...</td>\n      <td>This proposal suggests integrating Balancer Bo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[1IP-06] Donation of 1inch DAO Treasury Funds ...</td>\n      <td>1</td>\n      <td>The 1inch DAO Treasury is proposing to donate ...</td>\n      <td>The 1inch DAO is proposing to donate 1 million...</td>\n      <td>Summary. 1inch Network was founded on core val...</td>\n      <td>1646760014000</td>\n      <td>1647364814000</td>\n      <td>0x824732d3f4eb94a20254cca9de10485ce445bb40</td>\n      <td>1657200981507</td>\n      <td>...</td>\n      <td>0.042553</td>\n      <td>0.053864</td>\n      <td>4</td>\n      <td>77</td>\n      <td>150</td>\n      <td>14</td>\n      <td>0.297872</td>\n      <td>0.351288</td>\n      <td>The 1inch Network wants to donate $1 million f...</td>\n      <td>This proposal suggests donating 1 million USDC...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[Temperature Check] Should the Uniswap communi...</td>\n      <td>2</td>\n      <td>The Protocol Guild is a council of Ethereum pr...</td>\n      <td>The authors are proposing that 500,000 UNI (ab...</td>\n      <td>Authors: [Trent]([link]) (PG Member), [Tim]([l...</td>\n      <td>1654176425000</td>\n      <td>1654437600000</td>\n      <td>0x4c0a466df0628fe8699051b3ac6506653191cc21</td>\n      <td>1657200982022</td>\n      <td>...</td>\n      <td>0.034483</td>\n      <td>0.048402</td>\n      <td>10</td>\n      <td>317</td>\n      <td>384</td>\n      <td>20</td>\n      <td>0.344828</td>\n      <td>0.350685</td>\n      <td>The authors of this proposal are suggesting th...</td>\n      <td>This proposal suggests that the Uniswap commun...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Aave V3 Harmony - Freeze Reserves</td>\n      <td>3</td>\n      <td>The proposal is about freezing all reserves on...</td>\n      <td>The Aave DAO Community, through the governance...</td>\n      <td>title: Aave V3 Harmony - Freeze Reserves. stat...</td>\n      <td>1657807792000</td>\n      <td>1658138400000</td>\n      <td>0xd2362dbb5aa708bc454ce5c3f11050c016764fa6</td>\n      <td>1658239945117</td>\n      <td>...</td>\n      <td>0.043478</td>\n      <td>0.058394</td>\n      <td>5</td>\n      <td>34</td>\n      <td>100</td>\n      <td>17</td>\n      <td>0.369565</td>\n      <td>0.364964</td>\n      <td>This proposal by 3SE Holdings aims to address ...</td>\n      <td>The proposal suggests freezing all reserves in...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Revised ARC: Add 1INCH as collateral</td>\n      <td>3</td>\n      <td>The proposal seeks to add 1inch Networks 1INCH...</td>\n      <td>1inch Network is a decentralized set of protoc...</td>\n      <td>Summary. 1inch is a network of decentralized p...</td>\n      <td>1657638000000</td>\n      <td>1657983600000</td>\n      <td>0xc290cfb8d020c0615e9c63036f4319cc41717e68</td>\n      <td>1658239945766</td>\n      <td>...</td>\n      <td>0.042553</td>\n      <td>0.070053</td>\n      <td>3</td>\n      <td>430</td>\n      <td>588</td>\n      <td>19</td>\n      <td>0.404255</td>\n      <td>0.314439</td>\n      <td>This proposal suggests onboarding 1INCH, the t...</td>\n      <td>The proposal suggests adding the 1inch Network...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>805</td>\n      <td>[BIP-237] Enable USH - ETH 50/50 Gauge with 10...</td>\n      <td>12</td>\n      <td>This proposal is about adding a gauge to the n...</td>\n      <td>This proposal is about adding a gauge to the n...</td>\n      <td>[PR with Payload]([link]) Summary: Proposal to...</td>\n      <td>1680796800000</td>\n      <td>1681142400000</td>\n      <td>0x9f74662aD05840Ba35d111930501c617920dD68e</td>\n      <td>1680720307179</td>\n      <td>...</td>\n      <td>0.034783</td>\n      <td>0.042445</td>\n      <td>9</td>\n      <td>250</td>\n      <td>419</td>\n      <td>46</td>\n      <td>0.400000</td>\n      <td>0.355688</td>\n      <td>UnshETH, a project aimed at decentralizing cry...</td>\n      <td>This proposal suggests adding gauge support fo...</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>806</td>\n      <td>[BIP-239] Enable bb-a-USD gauge [Ethereum]</td>\n      <td>12</td>\n      <td>This passage is describing a proposal to add a...</td>\n      <td>This passage is describing a proposal to add a...</td>\n      <td>[PR with Payload]([link]) Summary This is a pr...</td>\n      <td>1680796800000</td>\n      <td>1681142400000</td>\n      <td>0x9f74662aD05840Ba35d111930501c617920dD68e</td>\n      <td>1680720307225</td>\n      <td>...</td>\n      <td>0.041237</td>\n      <td>0.067416</td>\n      <td>14</td>\n      <td>79</td>\n      <td>93</td>\n      <td>38</td>\n      <td>0.391753</td>\n      <td>0.348315</td>\n      <td>This proposal is about adding a new feature, c...</td>\n      <td>This proposal suggests adding a bb-a-USD gauge...</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>807</td>\n      <td>[BIP-240] Enable rETH/bb-a-wETH Gauge [Arbitrum]</td>\n      <td>12</td>\n      <td>This proposal is for a new pool on Arbitrum cr...</td>\n      <td>This proposal is for a new pool on Arbitrum cr...</td>\n      <td>[link] Summary: &gt; This pool uses the Composabl...</td>\n      <td>1680796800000</td>\n      <td>1681142400000</td>\n      <td>0x512fce9B07Ce64590849115EE6B32fd40eC0f5F3</td>\n      <td>1680776108847</td>\n      <td>...</td>\n      <td>0.039370</td>\n      <td>0.050773</td>\n      <td>18</td>\n      <td>243</td>\n      <td>137</td>\n      <td>46</td>\n      <td>0.362205</td>\n      <td>0.302428</td>\n      <td>This proposal suggests creating a new pool, rE...</td>\n      <td>This proposal suggests creating a new pool cal...</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>808</td>\n      <td>[BIP-241] Aave v3 Migration</td>\n      <td>12</td>\n      <td>This proposal is about transitioning from the ...</td>\n      <td>This proposal is about transitioning from the ...</td>\n      <td>[link] Motivation. &gt; With the Aave v3 linear p...</td>\n      <td>1680796800000</td>\n      <td>1681142400000</td>\n      <td>0x512fce9B07Ce64590849115EE6B32fd40eC0f5F3</td>\n      <td>1680777004583</td>\n      <td>...</td>\n      <td>0.042553</td>\n      <td>0.039171</td>\n      <td>9</td>\n      <td>286</td>\n      <td>139</td>\n      <td>38</td>\n      <td>0.404255</td>\n      <td>0.320276</td>\n      <td>This proposal is about transitioning from old ...</td>\n      <td>The proposal is to transition from the old Aav...</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>809</td>\n      <td>[1IP-26] Remove st1INCH(v1) Voting | Modify st...</td>\n      <td>1</td>\n      <td>This proposal is about modifying the 1inch DAO...</td>\n      <td>This proposal is about modifying the 1inch DAO...</td>\n      <td>Author: References: [[1IP-11] 1inch Staking Po...</td>\n      <td>1680789393000</td>\n      <td>1681221393000</td>\n      <td>0x824732D3F4Eb94a20254cca9DE10485Ce445Bb40</td>\n      <td>1680786006844</td>\n      <td>...</td>\n      <td>0.020619</td>\n      <td>0.041578</td>\n      <td>12</td>\n      <td>291</td>\n      <td>284</td>\n      <td>33</td>\n      <td>0.340206</td>\n      <td>0.302772</td>\n      <td>This proposal suggests changes to the 1inch DA...</td>\n      <td>This proposal suggests changes to the governan...</td>\n    </tr>\n  </tbody>\n</table>\n<p>683 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('data/summaries_GPT3_3_5_turbo_GPT4.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finetune GPT3.5 Turbo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                prompt  \\\n0    Simple Summary. This proposal calls for the in...   \n1    Summary. 1inch Network was founded on core val...   \n2    Authors: [Trent]([link]) (PG Member), [Tim]([l...   \n3    title: Aave V3 Harmony - Freeze Reserves. stat...   \n4    Summary. 1inch is a network of decentralized p...   \n..                                                 ...   \n678  [PR with Payload]([link]) Summary: Proposal to...   \n679  [PR with Payload]([link]) Summary This is a pr...   \n680  [link] Summary: > This pool uses the Composabl...   \n681  [link] Motivation. > With the Aave v3 linear p...   \n682  Author: References: [[1IP-11] 1inch Staking Po...   \n\n                                            completion  \n0    The proposal is about integrating Balancer Boo...  \n1    The 1inch DAO Treasury is proposing to donate ...  \n2    The Protocol Guild is a council of Ethereum pr...  \n3    The proposal is about freezing all reserves on...  \n4    The proposal seeks to add 1inch Networks 1INCH...  \n..                                                 ...  \n678  This proposal is about adding a gauge to the n...  \n679  This passage is describing a proposal to add a...  \n680  This proposal is for a new pool on Arbitrum cr...  \n681  This proposal is about transitioning from the ...  \n682  This proposal is about modifying the 1inch DAO...  \n\n[683 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>completion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Simple Summary. This proposal calls for the in...</td>\n      <td>The proposal is about integrating Balancer Boo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Summary. 1inch Network was founded on core val...</td>\n      <td>The 1inch DAO Treasury is proposing to donate ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Authors: [Trent]([link]) (PG Member), [Tim]([l...</td>\n      <td>The Protocol Guild is a council of Ethereum pr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>title: Aave V3 Harmony - Freeze Reserves. stat...</td>\n      <td>The proposal is about freezing all reserves on...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Summary. 1inch is a network of decentralized p...</td>\n      <td>The proposal seeks to add 1inch Networks 1INCH...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>[PR with Payload]([link]) Summary: Proposal to...</td>\n      <td>This proposal is about adding a gauge to the n...</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>[PR with Payload]([link]) Summary This is a pr...</td>\n      <td>This passage is describing a proposal to add a...</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>[link] Summary: &gt; This pool uses the Composabl...</td>\n      <td>This proposal is for a new pool on Arbitrum cr...</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>[link] Motivation. &gt; With the Aave v3 linear p...</td>\n      <td>This proposal is about transitioning from the ...</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>Author: References: [[1IP-11] 1inch Staking Po...</td>\n      <td>This proposal is about modifying the 1inch DAO...</td>\n    </tr>\n  </tbody>\n</table>\n<p>683 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_finetune = df[['seniorDescription', 'juniorDescription']].copy()\n",
    "\n",
    "# Rename the columns in 'df_finetune'\n",
    "df_finetune.columns = ['prompt', 'completion']\n",
    "df_finetune"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_finetune, test_size=0.2, random_state=42)\n",
    "train_df.to_json(\"data/df_finetune_train.jsonl\", orient=\"records\", lines=True)\n",
    "test_df.to_json(\"data/df_finetune_test.jsonl\", orient=\"records\", lines=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 546 prompt-completion pairs\n",
      "- There are 28 examples that are very long. These are rows: [31, 36, 47, 114, 115, 143, 165, 195, 199, 270, 307, 309, 315, 370, 420, 426, 428, 432, 434, 439, 445, 447, 450, 451, 463, 481, 488, 500]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 28 long examples [Y/n]: Y\n",
      "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
      "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `data/df_finetune_train_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"data/df_finetune_train_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 27.21 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f data/df_finetune_train.jsonl -q"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 137 prompt-completion pairs\n",
      "- There are 10 examples that are very long. These are rows: [2, 15, 17, 18, 34, 47, 61, 72, 92, 116]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 10 long examples [Y/n]: Y\n",
      "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
      "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `data/df_finetune_test_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"data/df_finetune_test_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.53 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f data/df_finetune_test.jsonl -q"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<OpenAIObject list at 0x1e1c58823b0> JSON: {\n  \"object\": \"list\",\n  \"data\": []\n}"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list OpenAI uploaded files\n",
    "openai.File.list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"data/df_finetune_train_prepared.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"data/df_finetune_valid_prepared.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Upload progress:   0%|          | 0.00/1.80M [00:00<?, ?it/s]\n",
      "Upload progress: 100%|##########| 1.80M/1.80M [00:00<00:00, 946Mit/s]\n",
      "\u001B[91mError:\u001B[0m HTTP code 500 from API (<html>\n",
      "  <head>\n",
      "    <title>Internal Server Error</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1><p>Internal Server Error</p></h1>\n",
      "    \n",
      "  </body>\n",
      "</html>\n",
      ") (HTTP status code: 500)\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t \"df_finetune_train_prepared.jsonl\" -v \"df_finetune_valid_prepared.jsonl\" -m curie"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'D:\\\\CVUT\\\\Diplom\\\\DIP\\\\data\\\\df_finetune_train_prepared.jsonl'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('data/df_finetune_train_prepared.jsonl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = openai.FineTune.create(\n",
    "    model=\"curie\",\n",
    "    training_file=os.path.abspath('data/df_finetune_train_prepared.jsonl'),\n",
    "    validation_file=os.path.abspath('data/df_finetune_valid_prepared.jsonl'),\n",
    ")\n",
    "job_id = response[\"id\"]\n",
    "status = response[\"status\"]\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_args = {\n",
    "\t\"training_file\": os.path.abspath('data/df_finetune_train_prepared.jsonl'),\n",
    "\t\"validation_file\": os.path.abspath('data/df_finetune_valid_prepared.jsonl'),\n",
    "\t\"model\": \"curie\",\n",
    "    \"max_tokens\": 250,\n",
    "\t# \"n_epochs\": 15,\n",
    "\t# \"batch_size\": 3,\n",
    "\t# \"learning_rate_multiplier\": 0.3\n",
    "}\n",
    "\n",
    "response = openai.FineTune.create(**create_args)\n",
    "job_id = response[\"id\"]\n",
    "status = response[\"status\"]\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
